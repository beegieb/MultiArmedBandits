# MultiArmedBandits
Collection of Multi Armed Bandit algorithms and a Simulator 
